{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import heapq\n",
    "import wandb\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.char2index = {}\n",
    "        self.char2count = {}\n",
    "        self.index2char = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_chars = 2  # Count SOS and EOS\n",
    "\n",
    "    def addWord(self, word):\n",
    "        for char in word:\n",
    "            self.addChar(char)\n",
    "\n",
    "    def addChar(self, char):\n",
    "        if char not in self.char2index:\n",
    "            self.char2index[char] = self.n_chars\n",
    "            self.char2count[char] = 1\n",
    "            self.index2char[self.n_chars] = char\n",
    "            self.n_chars += 1\n",
    "        else:\n",
    "            self.char2count[char] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang, type, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    \n",
    "    lines = open('aksharantar_sampled/%s/%s_%s.csv' % (lang, lang, type), encoding='utf-8').read().strip().split('\\n')\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    # pairs = [[normalizeString(s) for s in l.split(',')] for l in lines]\n",
    "    pairs = [[s for s in l.split(',')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang)\n",
    "        output_lang = Lang('eng')\n",
    "    else:\n",
    "        input_lang = Lang('eng')\n",
    "        output_lang = Lang(lang)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 10060 word pairs\n",
      "Trimmed to 10060 word pairs\n",
      "Counting chars...\n",
      "Counted chars:\n",
      "eng 28\n",
      "mni 46\n",
      "['kangleipakki', 'ꯀꯪꯂꯩꯄꯥꯛꯀꯤ']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang, reverse)\n",
    "    print(\"Read %s word pairs\" % len(pairs))\n",
    "    print(\"Trimmed to %s word pairs\" % len(pairs))\n",
    "    print(\"Counting chars...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addWord(pair[0])\n",
    "        output_lang.addWord(pair[1])\n",
    "    print(\"Counted chars:\")\n",
    "    print(input_lang.name, input_lang.n_chars)\n",
    "    print(output_lang.name, output_lang.n_chars)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('mni', 'train')\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = {'rnn': nn.RNN, 'gru': nn.GRU, 'lstm': nn.LSTM}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Class for the encoder RNN.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_hidden_layers, dropout=0.2, cell_type='gru'):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.cell_type = cell_type\n",
    "        self.cell = cells[cell_type](embedding_size, hidden_size, num_hidden_layers, dropout=dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell=None):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        if self.cell_type == 'rnn' or self.cell_type == 'gru':\n",
    "            output, hidden = self.cell(embedded, hidden)\n",
    "            return output, hidden\n",
    "        else:\n",
    "            output, (hidden, cell) = self.cell(embedded, (hidden, cell))    \n",
    "            return output, hidden, cell\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.num_hidden_layers, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamSearchNode:\n",
    "    def __init__(self, decoder_output, hidden, prev_node, char_idx, log_prob, length):\n",
    "        self.decoder_output = decoder_output\n",
    "        self.hidden = hidden\n",
    "        self.prev_node = prev_node\n",
    "        self.char_idx = char_idx\n",
    "        self.log_prob = log_prob\n",
    "        self.length = length\n",
    "\n",
    "    # def __lt__(self, other):\n",
    "    #     return self.log_prob > other.log_prob\n",
    "\n",
    "    def eval(self):\n",
    "        return self.log_prob / self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding_size, output_size, num_hidden_layers, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.output_size = output_size\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.embedding_size)\n",
    "        self.attn = nn.Linear(self.embedding_size + self.hidden_size, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.embedding_size + self.hidden_size, self.hidden_size)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size, self.num_hidden_layers, dropout=self.dropout_p)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.num_hidden_layers, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromWord(lang, word):\n",
    "    return [lang.char2index[char] for char in word]\n",
    "\n",
    "\n",
    "def tensorFromWord(lang, word):\n",
    "    indexes = indexesFromWord(lang, word)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromWord(input_lang, pair[0])\n",
    "    target_tensor = tensorFromWord(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    if encoder.cell_type == 'lstm':\n",
    "        encoder_cell = encoder.initHidden()\n",
    "        \n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        if encoder.cell_type == 'lstm':\n",
    "            encoder_output, encoder_hidden, encoder_cell = encoder(input_tensor[ei], encoder_hidden, encoder_cell)\n",
    "        else:\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    if decoder.cell_type == 'lstm':\n",
    "            decoder_cell = encoder_cell\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            if decoder.cell_type == 'lstm':\n",
    "                decoder_output, decoder_hidden, decoder_cell, decoder_attention = decoder(decoder_input, decoder_hidden, decoder_cell, encoder_outputs)\n",
    "            else:\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            \n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            if decoder.cell_type == 'lstm':\n",
    "                decoder_output, decoder_hidden, decoder_cell, decoder_attention = decoder(decoder_input, decoder_hidden, decoder_cell, encoder_outputs)\n",
    "            else:\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "                \n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, optimizer=optim.SGD, cell_type='gru', beam_width=1, print_every=1000, plot_every=100, learning_rate=5e-3):\n",
    "    start = time.time()\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "\n",
    "    encoder_optimizer = optimizer(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optimizer(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs)) for _ in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, cell_type, encoder_optimizer, decoder_optimizer, criterion, beam_width)\n",
    "        print_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters), iter, iter / n_iters * 100, print_loss_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, word, beam_width=1, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromWord(input_lang, word)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        if encoder.cell_type == 'lstm':\n",
    "            encoder_cell = encoder.initHidden()\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            if encoder.cell_type == 'lstm':\n",
    "                encoder_output, encoder_hidden, encoder_cell = encoder(input_tensor[ei], encoder_hidden, encoder_cell)\n",
    "            else:\n",
    "                encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        if decoder.cell_type == 'lstm':\n",
    "            decoder_cell = encoder_cell\n",
    "\n",
    "        decoded_chars = \"\"\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            if decoder.cell_type == 'lstm':\n",
    "                decoder_output, decoder_hidden, decoder_cell, decoder_attention = decoder(decoder_input, decoder_hidden, decoder_cell, encoder_outputs)\n",
    "            else:\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_chars += '<EOS>'\n",
    "                break\n",
    "            else:\n",
    "                decoded_chars += output_lang.index2char[topi.item()]\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_chars, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 3260 word pairs\n",
      "Trimmed to 3260 word pairs\n",
      "Counting chars...\n",
      "Counted chars:\n",
      "eng 28\n",
      "mni 46\n",
      "Reading lines...\n",
      "Read 4096 word pairs\n",
      "Trimmed to 4096 word pairs\n",
      "Counting chars...\n",
      "Counted chars:\n",
      "eng 28\n",
      "mni 46\n"
     ]
    }
   ],
   "source": [
    "input_valid_lang, output_valid_lang, valid_pairs = prepareData('mni', 'valid')\n",
    "input_test_lang, output_test_lang, test_pairs = prepareData('mni', 'test')\n",
    "\n",
    "def evalAccuracy(encoder, decoder, pairs):\n",
    "    correct = 0\n",
    "    for pair in pairs:\n",
    "        output_word = evaluate(encoder, decoder, pair[0])\n",
    "        output_word = output_word[:-5]\n",
    "        if output_word == pair[1]:\n",
    "            correct += 1\n",
    "    return correct / len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainBatch(encoder, decoder, epochs, optimizer=optim.SGD, beam_width=1, print_every=1000, learning_rate=5e-3, log=False):\n",
    "    start = time.time()\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "\n",
    "    encoder_optimizer = optimizer(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optimizer(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(pair) for pair in pairs]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    # print(\"Training pairs:\", len(training_pairs))\n",
    "\n",
    "    for iter in range(1, len(training_pairs) * epochs + 1):\n",
    "        training_pair = training_pairs[(iter - 1) % len(training_pairs)]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, beam_width)\n",
    "        print_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / (len(training_pairs) * epochs)), iter, iter / (len(training_pairs) * epochs) * 100, print_loss_avg))\n",
    "\n",
    "        if log:\n",
    "            wandb.log({\"train_loss\": loss})\n",
    "\n",
    "            if iter % len(training_pairs) == 0:\n",
    "                wandb.log({\"train_accuracy\": evalAccuracy(encoder, decoder, pairs), \"val_accuracy\": evalAccuracy(encoder, decoder, valid_pairs), \"epoch\": iter / len(training_pairs)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        # output_chars, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_word = evaluate(encoder, decoder, pair[0])\n",
    "        # output_word = ''.join(output_chars)\n",
    "        print('<', output_word)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdullah/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "AttnDecoderRNN.__init__() got an unexpected keyword argument 'cell_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/abdullah/Desktop/Courses/Sem6/CS6910/A3/A3_attention.ipynb Cell 18\u001b[0m in \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/abdullah/Desktop/Courses/Sem6/CS6910/A3/A3_attention.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m embedding_size \u001b[39m=\u001b[39m \u001b[39m256\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/abdullah/Desktop/Courses/Sem6/CS6910/A3/A3_attention.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m encoder1 \u001b[39m=\u001b[39m EncoderRNN(input_lang\u001b[39m.\u001b[39mn_chars, embedding_size, hidden_size, num_hidden_layers\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, cell_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgru\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/abdullah/Desktop/Courses/Sem6/CS6910/A3/A3_attention.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m decoder1 \u001b[39m=\u001b[39m AttnDecoderRNN(hidden_size, embedding_size, output_lang\u001b[39m.\u001b[39;49mn_chars, num_hidden_layers\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, cell_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgru\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;31mTypeError\u001b[0m: AttnDecoderRNN.__init__() got an unexpected keyword argument 'cell_type'"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "# embedding_size = input_lang.n_chars\n",
    "embedding_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_chars, embedding_size, hidden_size, num_hidden_layers=1, cell_type='gru').to(device)\n",
    "decoder1 = AttnDecoderRNN(hidden_size, embedding_size, output_lang.n_chars, num_hidden_layers=1, cell_type='gru').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainIters(encoder1, decoder1, n_iters=1, beam_width=5, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 1s (- 9m 55s) (100 0%) 2.6452\n",
      "0m 2s (- 9m 39s) (200 0%) 2.7250\n",
      "0m 4s (- 9m 29s) (300 0%) 2.8955\n",
      "0m 5s (- 9m 42s) (400 0%) 2.6631\n",
      "0m 7s (- 9m 30s) (500 1%) 2.7041\n",
      "0m 8s (- 9m 28s) (600 1%) 2.6729\n",
      "0m 9s (- 9m 16s) (700 1%) 2.6407\n",
      "0m 11s (- 9m 5s) (800 1%) 2.6048\n",
      "0m 12s (- 8m 58s) (900 2%) 2.6655\n",
      "0m 13s (- 8m 50s) (1000 2%) 2.6220\n",
      "0m 15s (- 9m 4s) (1100 2%) 2.7234\n",
      "0m 17s (- 9m 17s) (1200 2%) 2.6269\n",
      "0m 18s (- 9m 26s) (1300 3%) 2.6035\n",
      "0m 20s (- 9m 42s) (1400 3%) 2.6171\n",
      "0m 22s (- 9m 53s) (1500 3%) 2.5768\n",
      "0m 24s (- 9m 43s) (1600 3%) 2.5544\n",
      "0m 25s (- 9m 32s) (1700 4%) 2.5816\n",
      "0m 26s (- 9m 21s) (1800 4%) 2.6929\n",
      "0m 27s (- 9m 12s) (1900 4%) 2.6096\n",
      "0m 28s (- 9m 5s) (2000 4%) 2.5607\n",
      "0m 29s (- 8m 59s) (2100 5%) 2.6524\n",
      "0m 30s (- 8m 53s) (2200 5%) 2.5363\n",
      "0m 32s (- 8m 48s) (2300 5%) 2.6139\n",
      "0m 33s (- 8m 43s) (2400 5%) 2.5911\n",
      "0m 34s (- 8m 38s) (2500 6%) 2.6466\n",
      "0m 35s (- 8m 32s) (2600 6%) 2.6185\n",
      "0m 36s (- 8m 28s) (2700 6%) 2.5745\n",
      "0m 37s (- 8m 23s) (2800 6%) 2.5042\n",
      "0m 38s (- 8m 18s) (2900 7%) 2.5636\n",
      "0m 39s (- 8m 13s) (3000 7%) 2.5074\n",
      "0m 40s (- 8m 9s) (3100 7%) 2.5441\n",
      "0m 42s (- 8m 6s) (3200 7%) 2.5418\n",
      "0m 43s (- 8m 2s) (3300 8%) 2.5907\n",
      "0m 44s (- 7m 59s) (3400 8%) 2.4673\n",
      "0m 45s (- 8m 0s) (3500 8%) 2.4426\n",
      "0m 47s (- 8m 2s) (3600 8%) 2.4196\n",
      "0m 48s (- 8m 1s) (3700 9%) 2.4048\n",
      "0m 50s (- 8m 2s) (3800 9%) 2.4615\n",
      "0m 51s (- 8m 2s) (3900 9%) 2.4036\n",
      "0m 52s (- 7m 59s) (4000 9%) 2.3590\n",
      "0m 54s (- 7m 56s) (4100 10%) 2.4101\n",
      "0m 55s (- 7m 54s) (4200 10%) 2.4061\n",
      "0m 56s (- 7m 52s) (4300 10%) 2.3997\n",
      "0m 58s (- 7m 53s) (4400 10%) 2.3592\n",
      "0m 59s (- 7m 50s) (4500 11%) 2.2610\n",
      "1m 0s (- 7m 46s) (4600 11%) 2.3088\n",
      "1m 1s (- 7m 43s) (4700 11%) 2.3336\n",
      "1m 2s (- 7m 41s) (4800 11%) 2.1687\n",
      "1m 3s (- 7m 39s) (4900 12%) 2.3336\n",
      "1m 4s (- 7m 36s) (5000 12%) 2.1077\n",
      "1m 5s (- 7m 34s) (5100 12%) 2.1606\n",
      "1m 7s (- 7m 31s) (5200 12%) 2.1615\n",
      "1m 8s (- 7m 29s) (5300 13%) 2.0661\n",
      "1m 9s (- 7m 27s) (5400 13%) 2.1438\n",
      "1m 10s (- 7m 24s) (5500 13%) 2.1442\n",
      "1m 11s (- 7m 25s) (5600 13%) 2.1296\n",
      "1m 13s (- 7m 26s) (5700 14%) 2.0680\n",
      "1m 15s (- 7m 26s) (5800 14%) 1.9291\n",
      "1m 16s (- 7m 26s) (5900 14%) 2.0043\n",
      "1m 17s (- 7m 24s) (6000 14%) 2.0543\n",
      "1m 19s (- 7m 22s) (6100 15%) 1.9805\n",
      "1m 20s (- 7m 22s) (6200 15%) 1.9786\n",
      "1m 21s (- 7m 20s) (6300 15%) 1.9993\n",
      "1m 22s (- 7m 18s) (6400 15%) 1.9916\n",
      "1m 24s (- 7m 17s) (6500 16%) 1.9467\n",
      "1m 27s (- 7m 24s) (6600 16%) 1.9899\n",
      "1m 30s (- 7m 31s) (6700 16%) 2.0007\n",
      "1m 31s (- 7m 32s) (6800 16%) 1.9598\n",
      "1m 33s (- 7m 30s) (6900 17%) 1.8677\n",
      "1m 34s (- 7m 28s) (7000 17%) 1.8873\n",
      "1m 35s (- 7m 26s) (7100 17%) 1.8545\n",
      "1m 36s (- 7m 24s) (7200 17%) 1.8280\n",
      "1m 38s (- 7m 24s) (7300 18%) 1.9167\n",
      "1m 39s (- 7m 22s) (7400 18%) 1.7678\n",
      "1m 41s (- 7m 22s) (7500 18%) 1.8087\n",
      "1m 42s (- 7m 19s) (7600 18%) 1.8196\n",
      "1m 43s (- 7m 17s) (7700 19%) 1.8189\n",
      "1m 44s (- 7m 15s) (7800 19%) 1.8202\n",
      "1m 45s (- 7m 12s) (7900 19%) 1.8225\n",
      "1m 46s (- 7m 10s) (8000 19%) 1.7567\n",
      "1m 47s (- 7m 8s) (8100 20%) 1.7794\n",
      "1m 49s (- 7m 6s) (8200 20%) 1.9722\n",
      "1m 50s (- 7m 5s) (8300 20%) 1.7290\n",
      "1m 51s (- 7m 3s) (8400 20%) 1.8052\n",
      "1m 52s (- 7m 1s) (8500 21%) 1.7446\n",
      "1m 54s (- 7m 0s) (8600 21%) 1.7130\n",
      "1m 55s (- 6m 58s) (8700 21%) 1.7415\n",
      "1m 56s (- 6m 56s) (8800 21%) 1.7188\n",
      "1m 57s (- 6m 54s) (8900 22%) 1.7295\n",
      "1m 58s (- 6m 52s) (9000 22%) 1.6695\n",
      "1m 59s (- 6m 50s) (9100 22%) 1.6215\n",
      "2m 1s (- 6m 49s) (9200 22%) 1.6772\n",
      "2m 3s (- 6m 49s) (9300 23%) 1.8154\n",
      "2m 4s (- 6m 48s) (9400 23%) 1.6166\n",
      "2m 5s (- 6m 46s) (9500 23%) 1.6456\n",
      "2m 6s (- 6m 44s) (9600 23%) 1.5789\n",
      "2m 7s (- 6m 42s) (9700 24%) 1.5828\n",
      "2m 9s (- 6m 41s) (9800 24%) 1.6793\n",
      "2m 10s (- 6m 39s) (9900 24%) 1.6001\n",
      "2m 11s (- 6m 37s) (10000 24%) 1.6252\n",
      "2m 12s (- 6m 35s) (10100 25%) 1.7253\n",
      "2m 13s (- 6m 33s) (10200 25%) 1.4734\n",
      "2m 14s (- 6m 32s) (10300 25%) 1.6051\n",
      "2m 16s (- 6m 31s) (10400 25%) 1.5468\n",
      "2m 17s (- 6m 29s) (10500 26%) 1.4379\n",
      "2m 19s (- 6m 28s) (10600 26%) 1.5637\n",
      "2m 20s (- 6m 27s) (10700 26%) 1.4670\n",
      "2m 21s (- 6m 25s) (10800 26%) 1.4778\n",
      "2m 22s (- 6m 23s) (10900 27%) 1.4515\n",
      "2m 23s (- 6m 22s) (11000 27%) 1.4763\n",
      "2m 25s (- 6m 20s) (11100 27%) 1.5231\n",
      "2m 26s (- 6m 19s) (11200 27%) 1.5810\n",
      "2m 27s (- 6m 17s) (11300 28%) 1.5989\n",
      "2m 28s (- 6m 16s) (11400 28%) 1.5432\n",
      "2m 29s (- 6m 14s) (11500 28%) 1.4321\n",
      "2m 31s (- 6m 13s) (11600 28%) 1.4573\n",
      "2m 32s (- 6m 11s) (11700 29%) 1.3499\n",
      "2m 33s (- 6m 10s) (11800 29%) 1.4223\n",
      "2m 34s (- 6m 8s) (11900 29%) 1.4473\n",
      "2m 35s (- 6m 6s) (12000 29%) 1.4816\n",
      "2m 37s (- 6m 5s) (12100 30%) 1.4862\n",
      "2m 38s (- 6m 4s) (12200 30%) 1.4228\n",
      "2m 41s (- 6m 5s) (12300 30%) 1.3314\n",
      "2m 43s (- 6m 6s) (12400 30%) 1.3654\n",
      "2m 44s (- 6m 5s) (12500 31%) 1.3832\n",
      "2m 45s (- 6m 3s) (12600 31%) 1.2628\n",
      "2m 46s (- 6m 1s) (12700 31%) 1.2722\n",
      "2m 47s (- 6m 0s) (12800 31%) 1.2762\n",
      "2m 49s (- 5m 58s) (12900 32%) 1.2396\n",
      "2m 50s (- 5m 56s) (13000 32%) 1.3984\n",
      "2m 51s (- 5m 54s) (13100 32%) 1.2099\n",
      "2m 52s (- 5m 53s) (13200 32%) 1.2974\n",
      "2m 53s (- 5m 51s) (13300 33%) 1.2225\n",
      "2m 55s (- 5m 50s) (13400 33%) 1.1902\n",
      "2m 56s (- 5m 49s) (13500 33%) 1.3219\n",
      "2m 57s (- 5m 47s) (13600 33%) 1.3915\n",
      "2m 58s (- 5m 45s) (13700 34%) 1.1792\n",
      "2m 59s (- 5m 44s) (13800 34%) 1.2559\n",
      "3m 0s (- 5m 42s) (13900 34%) 1.2835\n",
      "3m 1s (- 5m 41s) (14000 34%) 1.1876\n",
      "3m 3s (- 5m 39s) (14100 35%) 1.3653\n",
      "3m 4s (- 5m 38s) (14200 35%) 1.2421\n",
      "3m 5s (- 5m 36s) (14300 35%) 1.2526\n",
      "3m 6s (- 5m 35s) (14400 35%) 1.1574\n",
      "3m 8s (- 5m 34s) (14500 36%) 1.1833\n",
      "3m 9s (- 5m 33s) (14600 36%) 1.1658\n",
      "3m 11s (- 5m 32s) (14700 36%) 1.2900\n",
      "3m 12s (- 5m 31s) (14800 36%) 1.2029\n",
      "3m 14s (- 5m 30s) (14900 37%) 1.2008\n",
      "3m 15s (- 5m 29s) (15000 37%) 1.0919\n",
      "3m 16s (- 5m 27s) (15100 37%) 1.1362\n",
      "3m 18s (- 5m 26s) (15200 37%) 1.2366\n",
      "3m 19s (- 5m 25s) (15300 38%) 1.1408\n",
      "3m 20s (- 5m 23s) (15400 38%) 0.9569\n",
      "3m 22s (- 5m 22s) (15500 38%) 1.1526\n",
      "3m 23s (- 5m 21s) (15600 38%) 1.0796\n",
      "3m 25s (- 5m 20s) (15700 39%) 1.1798\n",
      "3m 26s (- 5m 20s) (15800 39%) 1.0556\n",
      "3m 28s (- 5m 19s) (15900 39%) 1.0060\n",
      "3m 29s (- 5m 17s) (16000 39%) 1.1038\n",
      "3m 30s (- 5m 16s) (16100 40%) 1.0141\n",
      "3m 32s (- 5m 15s) (16200 40%) 1.0571\n",
      "3m 34s (- 5m 14s) (16300 40%) 1.0838\n",
      "3m 35s (- 5m 13s) (16400 40%) 1.1014\n",
      "3m 37s (- 5m 12s) (16500 41%) 1.1701\n",
      "3m 38s (- 5m 11s) (16600 41%) 1.2085\n",
      "3m 39s (- 5m 10s) (16700 41%) 1.1104\n",
      "3m 41s (- 5m 8s) (16800 41%) 1.1863\n",
      "3m 43s (- 5m 8s) (16900 41%) 1.0649\n",
      "3m 44s (- 5m 7s) (17000 42%) 1.0783\n",
      "3m 46s (- 5m 6s) (17100 42%) 0.9389\n",
      "3m 47s (- 5m 4s) (17200 42%) 1.0046\n",
      "3m 48s (- 5m 3s) (17300 42%) 0.9989\n",
      "3m 49s (- 5m 1s) (17400 43%) 1.0287\n",
      "3m 50s (- 4m 59s) (17500 43%) 1.0094\n",
      "3m 52s (- 4m 58s) (17600 43%) 0.9655\n",
      "3m 53s (- 4m 57s) (17700 43%) 1.0602\n",
      "3m 54s (- 4m 55s) (17800 44%) 1.0510\n",
      "3m 55s (- 4m 54s) (17900 44%) 0.9959\n",
      "3m 58s (- 4m 54s) (18000 44%) 0.9645\n",
      "3m 59s (- 4m 52s) (18100 44%) 1.0016\n",
      "4m 0s (- 4m 51s) (18200 45%) 0.8942\n",
      "4m 1s (- 4m 49s) (18300 45%) 1.0146\n",
      "4m 2s (- 4m 48s) (18400 45%) 1.0460\n",
      "4m 4s (- 4m 46s) (18500 45%) 1.0934\n",
      "4m 5s (- 4m 45s) (18600 46%) 1.0014\n",
      "4m 6s (- 4m 43s) (18700 46%) 1.1049\n",
      "4m 7s (- 4m 42s) (18800 46%) 1.0624\n",
      "4m 8s (- 4m 41s) (18900 46%) 0.9404\n",
      "4m 10s (- 4m 39s) (19000 47%) 0.9343\n",
      "4m 11s (- 4m 38s) (19100 47%) 0.9208\n",
      "4m 12s (- 4m 36s) (19200 47%) 0.8478\n",
      "4m 13s (- 4m 35s) (19300 47%) 1.0127\n",
      "4m 15s (- 4m 34s) (19400 48%) 1.0353\n",
      "4m 16s (- 4m 32s) (19500 48%) 0.9332\n",
      "4m 17s (- 4m 31s) (19600 48%) 0.7523\n",
      "4m 18s (- 4m 29s) (19700 48%) 0.9246\n",
      "4m 19s (- 4m 28s) (19800 49%) 0.8975\n",
      "4m 21s (- 4m 26s) (19900 49%) 1.0104\n",
      "4m 22s (- 4m 25s) (20000 49%) 0.9120\n",
      "4m 23s (- 4m 24s) (20100 49%) 0.9606\n",
      "4m 24s (- 4m 22s) (20200 50%) 0.8312\n",
      "4m 26s (- 4m 21s) (20300 50%) 0.9478\n",
      "4m 27s (- 4m 20s) (20400 50%) 0.9426\n",
      "4m 29s (- 4m 19s) (20500 50%) 0.8805\n",
      "4m 30s (- 4m 18s) (20600 51%) 0.7818\n",
      "4m 31s (- 4m 16s) (20700 51%) 0.9301\n",
      "4m 33s (- 4m 15s) (20800 51%) 0.8514\n",
      "4m 34s (- 4m 13s) (20900 51%) 0.8716\n",
      "4m 35s (- 4m 12s) (21000 52%) 0.9023\n",
      "4m 36s (- 4m 11s) (21100 52%) 0.9814\n",
      "4m 38s (- 4m 10s) (21200 52%) 0.8759\n",
      "4m 40s (- 4m 9s) (21300 52%) 0.9261\n",
      "4m 42s (- 4m 8s) (21400 53%) 1.0231\n",
      "4m 43s (- 4m 7s) (21500 53%) 0.9139\n",
      "4m 45s (- 4m 6s) (21600 53%) 0.7936\n",
      "4m 46s (- 4m 4s) (21700 53%) 0.8623\n",
      "4m 48s (- 4m 3s) (21800 54%) 0.8065\n",
      "4m 49s (- 4m 2s) (21900 54%) 0.7906\n",
      "4m 50s (- 4m 1s) (22000 54%) 0.9288\n",
      "4m 52s (- 3m 59s) (22100 54%) 0.6916\n",
      "4m 53s (- 3m 58s) (22200 55%) 0.8043\n",
      "4m 55s (- 3m 57s) (22300 55%) 0.7810\n",
      "4m 56s (- 3m 55s) (22400 55%) 0.7995\n",
      "4m 57s (- 3m 54s) (22500 55%) 0.7616\n",
      "4m 58s (- 3m 53s) (22600 56%) 0.8598\n",
      "4m 59s (- 3m 51s) (22700 56%) 0.6017\n",
      "5m 1s (- 3m 50s) (22800 56%) 0.7186\n",
      "5m 2s (- 3m 48s) (22900 56%) 0.7571\n",
      "5m 3s (- 3m 47s) (23000 57%) 0.8711\n",
      "5m 4s (- 3m 45s) (23100 57%) 0.8703\n",
      "5m 5s (- 3m 44s) (23200 57%) 0.8087\n",
      "5m 6s (- 3m 43s) (23300 57%) 0.7790\n",
      "5m 8s (- 3m 41s) (23400 58%) 0.7790\n",
      "5m 9s (- 3m 40s) (23500 58%) 0.8502\n",
      "5m 11s (- 3m 39s) (23600 58%) 0.8501\n",
      "5m 12s (- 3m 37s) (23700 58%) 0.7966\n",
      "5m 13s (- 3m 36s) (23800 59%) 0.7848\n",
      "5m 14s (- 3m 35s) (23900 59%) 0.7513\n",
      "5m 16s (- 3m 33s) (24000 59%) 0.7811\n",
      "5m 17s (- 3m 32s) (24100 59%) 0.7179\n",
      "5m 18s (- 3m 31s) (24200 60%) 0.8806\n",
      "5m 19s (- 3m 29s) (24300 60%) 0.7379\n",
      "5m 20s (- 3m 28s) (24400 60%) 0.8560\n",
      "5m 22s (- 3m 27s) (24500 60%) 0.7125\n",
      "5m 23s (- 3m 25s) (24600 61%) 0.7204\n",
      "5m 24s (- 3m 24s) (24700 61%) 0.6658\n",
      "5m 25s (- 3m 22s) (24800 61%) 0.8700\n",
      "5m 27s (- 3m 21s) (24900 61%) 0.8437\n",
      "5m 28s (- 3m 20s) (25000 62%) 0.6484\n",
      "5m 30s (- 3m 19s) (25100 62%) 0.7003\n",
      "5m 31s (- 3m 17s) (25200 62%) 0.8501\n",
      "5m 33s (- 3m 16s) (25300 62%) 0.6514\n",
      "5m 34s (- 3m 15s) (25400 63%) 0.6685\n",
      "5m 35s (- 3m 13s) (25500 63%) 0.7261\n",
      "5m 36s (- 3m 12s) (25600 63%) 0.7949\n",
      "5m 38s (- 3m 11s) (25700 63%) 0.7292\n",
      "5m 39s (- 3m 9s) (25800 64%) 0.7740\n",
      "5m 40s (- 3m 8s) (25900 64%) 0.8435\n",
      "5m 41s (- 3m 7s) (26000 64%) 0.6498\n",
      "5m 42s (- 3m 5s) (26100 64%) 0.7259\n",
      "5m 43s (- 3m 4s) (26200 65%) 0.5962\n",
      "5m 45s (- 3m 2s) (26300 65%) 0.6812\n",
      "5m 46s (- 3m 1s) (26400 65%) 0.6831\n",
      "5m 47s (- 3m 0s) (26500 65%) 0.7464\n",
      "5m 49s (- 2m 58s) (26600 66%) 0.7370\n",
      "5m 50s (- 2m 57s) (26700 66%) 0.8384\n",
      "5m 52s (- 2m 56s) (26800 66%) 0.8236\n",
      "5m 53s (- 2m 55s) (26900 66%) 0.6728\n",
      "5m 54s (- 2m 53s) (27000 67%) 0.7282\n",
      "5m 55s (- 2m 52s) (27100 67%) 0.6920\n",
      "5m 56s (- 2m 51s) (27200 67%) 0.7412\n",
      "5m 58s (- 2m 49s) (27300 67%) 0.6294\n",
      "5m 59s (- 2m 48s) (27400 68%) 0.7569\n",
      "6m 0s (- 2m 47s) (27500 68%) 0.7742\n",
      "6m 1s (- 2m 45s) (27600 68%) 0.6379\n",
      "6m 3s (- 2m 44s) (27700 68%) 0.7594\n",
      "6m 4s (- 2m 42s) (27800 69%) 0.6790\n",
      "6m 5s (- 2m 41s) (27900 69%) 0.7857\n",
      "6m 6s (- 2m 40s) (28000 69%) 0.6669\n",
      "6m 8s (- 2m 39s) (28100 69%) 0.6541\n",
      "6m 10s (- 2m 38s) (28200 70%) 0.6529\n",
      "6m 12s (- 2m 37s) (28300 70%) 0.6672\n",
      "6m 13s (- 2m 35s) (28400 70%) 0.7358\n",
      "6m 15s (- 2m 34s) (28500 70%) 0.7724\n",
      "6m 16s (- 2m 33s) (28600 71%) 0.8353\n",
      "6m 17s (- 2m 31s) (28700 71%) 0.7252\n",
      "6m 19s (- 2m 30s) (28800 71%) 0.8403\n",
      "6m 20s (- 2m 29s) (28900 71%) 0.7276\n",
      "6m 21s (- 2m 28s) (29000 72%) 0.7264\n",
      "6m 23s (- 2m 26s) (29100 72%) 0.5819\n",
      "6m 24s (- 2m 25s) (29200 72%) 0.5603\n",
      "6m 25s (- 2m 23s) (29300 72%) 0.6472\n",
      "6m 26s (- 2m 22s) (29400 73%) 0.7349\n",
      "6m 27s (- 2m 21s) (29500 73%) 0.6881\n",
      "6m 29s (- 2m 19s) (29600 73%) 0.5180\n",
      "6m 30s (- 2m 18s) (29700 73%) 0.6292\n",
      "6m 31s (- 2m 17s) (29800 74%) 0.5784\n",
      "6m 33s (- 2m 15s) (29900 74%) 0.5811\n",
      "6m 34s (- 2m 14s) (30000 74%) 0.7439\n",
      "6m 35s (- 2m 13s) (30100 74%) 0.7079\n",
      "6m 37s (- 2m 12s) (30200 75%) 0.8353\n",
      "6m 38s (- 2m 10s) (30300 75%) 0.6848\n",
      "6m 40s (- 2m 9s) (30400 75%) 0.6808\n",
      "6m 41s (- 2m 8s) (30500 75%) 0.7080\n",
      "6m 42s (- 2m 6s) (30600 76%) 0.5347\n",
      "6m 43s (- 2m 5s) (30700 76%) 0.6008\n",
      "6m 45s (- 2m 4s) (30800 76%) 0.6301\n",
      "6m 46s (- 2m 2s) (30900 76%) 0.5314\n",
      "6m 47s (- 2m 1s) (31000 77%) 0.5471\n",
      "6m 48s (- 2m 0s) (31100 77%) 0.6785\n",
      "6m 50s (- 1m 58s) (31200 77%) 0.7079\n",
      "6m 51s (- 1m 57s) (31300 77%) 0.6449\n",
      "6m 53s (- 1m 56s) (31400 78%) 0.7461\n",
      "6m 54s (- 1m 55s) (31500 78%) 0.7590\n",
      "6m 56s (- 1m 53s) (31600 78%) 0.7454\n",
      "6m 57s (- 1m 52s) (31700 78%) 0.5179\n",
      "6m 58s (- 1m 51s) (31800 79%) 0.5613\n",
      "7m 0s (- 1m 49s) (31900 79%) 0.5011\n",
      "7m 1s (- 1m 48s) (32000 79%) 0.6411\n",
      "7m 2s (- 1m 47s) (32100 79%) 0.6254\n",
      "7m 3s (- 1m 45s) (32200 80%) 0.6345\n",
      "7m 4s (- 1m 44s) (32300 80%) 0.5271\n",
      "7m 6s (- 1m 43s) (32400 80%) 0.6822\n",
      "7m 8s (- 1m 41s) (32500 80%) 0.5970\n",
      "7m 9s (- 1m 40s) (32600 81%) 0.5567\n",
      "7m 11s (- 1m 39s) (32700 81%) 0.5915\n",
      "7m 12s (- 1m 38s) (32800 81%) 0.5094\n",
      "7m 14s (- 1m 36s) (32900 81%) 0.5240\n",
      "7m 15s (- 1m 35s) (33000 82%) 0.4422\n",
      "7m 17s (- 1m 34s) (33100 82%) 0.7178\n",
      "7m 18s (- 1m 33s) (33200 82%) 0.6078\n",
      "7m 20s (- 1m 31s) (33300 82%) 0.6043\n",
      "7m 21s (- 1m 30s) (33400 83%) 0.5256\n",
      "7m 23s (- 1m 29s) (33500 83%) 0.5893\n",
      "7m 24s (- 1m 27s) (33600 83%) 0.6185\n",
      "7m 25s (- 1m 26s) (33700 83%) 0.7160\n",
      "7m 26s (- 1m 25s) (33800 83%) 0.6264\n",
      "7m 27s (- 1m 23s) (33900 84%) 0.4783\n",
      "7m 29s (- 1m 22s) (34000 84%) 0.6625\n",
      "7m 32s (- 1m 21s) (34100 84%) 0.6236\n",
      "7m 34s (- 1m 20s) (34200 84%) 0.5552\n",
      "7m 35s (- 1m 18s) (34300 85%) 0.7488\n",
      "7m 36s (- 1m 17s) (34400 85%) 0.5057\n",
      "7m 37s (- 1m 16s) (34500 85%) 0.6105\n",
      "7m 39s (- 1m 14s) (34600 85%) 0.5188\n",
      "7m 40s (- 1m 13s) (34700 86%) 0.4708\n",
      "7m 42s (- 1m 12s) (34800 86%) 0.6276\n",
      "7m 43s (- 1m 10s) (34900 86%) 0.6605\n",
      "7m 44s (- 1m 9s) (35000 86%) 0.6755\n",
      "7m 46s (- 1m 8s) (35100 87%) 0.5719\n",
      "7m 47s (- 1m 6s) (35200 87%) 0.4991\n",
      "7m 48s (- 1m 5s) (35300 87%) 0.5756\n",
      "7m 49s (- 1m 4s) (35400 87%) 0.5948\n",
      "7m 50s (- 1m 2s) (35500 88%) 0.4481\n",
      "7m 52s (- 1m 1s) (35600 88%) 0.5460\n",
      "7m 53s (- 1m 0s) (35700 88%) 0.4593\n",
      "7m 54s (- 0m 58s) (35800 88%) 0.4818\n",
      "7m 55s (- 0m 57s) (35900 89%) 0.5835\n",
      "7m 56s (- 0m 56s) (36000 89%) 0.5464\n",
      "7m 57s (- 0m 54s) (36100 89%) 0.4971\n",
      "7m 58s (- 0m 53s) (36200 89%) 0.5149\n",
      "8m 0s (- 0m 52s) (36300 90%) 0.4982\n",
      "8m 1s (- 0m 50s) (36400 90%) 0.4526\n",
      "8m 2s (- 0m 49s) (36500 90%) 0.5574\n",
      "8m 3s (- 0m 48s) (36600 90%) 0.5739\n",
      "8m 5s (- 0m 46s) (36700 91%) 0.6798\n",
      "8m 7s (- 0m 45s) (36800 91%) 0.4782\n",
      "8m 8s (- 0m 44s) (36900 91%) 0.5769\n",
      "8m 10s (- 0m 42s) (37000 91%) 0.5416\n",
      "8m 11s (- 0m 41s) (37100 92%) 0.6885\n",
      "8m 13s (- 0m 40s) (37200 92%) 0.4102\n",
      "8m 14s (- 0m 38s) (37300 92%) 0.4862\n",
      "8m 16s (- 0m 37s) (37400 92%) 0.5116\n",
      "8m 17s (- 0m 36s) (37500 93%) 0.6006\n",
      "8m 18s (- 0m 35s) (37600 93%) 0.5265\n",
      "8m 19s (- 0m 33s) (37700 93%) 0.5280\n",
      "8m 20s (- 0m 32s) (37800 93%) 0.5827\n",
      "8m 22s (- 0m 30s) (37900 94%) 0.5020\n",
      "8m 23s (- 0m 29s) (38000 94%) 0.5725\n",
      "8m 24s (- 0m 28s) (38100 94%) 0.5657\n",
      "8m 25s (- 0m 26s) (38200 94%) 0.5475\n",
      "8m 27s (- 0m 25s) (38300 95%) 0.4701\n",
      "8m 29s (- 0m 24s) (38400 95%) 0.5865\n",
      "8m 30s (- 0m 23s) (38500 95%) 0.5628\n",
      "8m 32s (- 0m 21s) (38600 95%) 0.7073\n",
      "8m 33s (- 0m 20s) (38700 96%) 0.5134\n",
      "8m 34s (- 0m 19s) (38800 96%) 0.6022\n",
      "8m 35s (- 0m 17s) (38900 96%) 0.6415\n",
      "8m 37s (- 0m 16s) (39000 96%) 0.5765\n",
      "8m 38s (- 0m 15s) (39100 97%) 0.4433\n",
      "8m 39s (- 0m 13s) (39200 97%) 0.6691\n",
      "8m 41s (- 0m 12s) (39300 97%) 0.5302\n",
      "8m 42s (- 0m 11s) (39400 97%) 0.4475\n",
      "8m 44s (- 0m 9s) (39500 98%) 0.5815\n",
      "8m 45s (- 0m 8s) (39600 98%) 0.5276\n",
      "8m 46s (- 0m 7s) (39700 98%) 0.3665\n",
      "8m 47s (- 0m 5s) (39800 98%) 0.4880\n",
      "8m 49s (- 0m 4s) (39900 99%) 0.4005\n",
      "8m 50s (- 0m 3s) (40000 99%) 0.5019\n",
      "8m 51s (- 0m 1s) (40100 99%) 0.5841\n",
      "8m 53s (- 0m 0s) (40200 99%) 0.5687\n"
     ]
    }
   ],
   "source": [
    "trainBatch(encoder1, decoder1, epochs=4, beam_width=1, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1256,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder2 = EncoderRNN(input_lang.n_chars, embedding_size, hidden_size, num_hidden_layers=2, cell_type='gru').to(device)\n",
    "decoder2 = DecoderRNN(hidden_size, embedding_size, output_lang.n_chars, num_hidden_layers=2, cell_type='gru').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 2s (- 16m 10s) (100 0%) 2.7145\n",
      "0m 5s (- 17m 32s) (200 0%) 2.7649\n",
      "0m 7s (- 17m 31s) (300 0%) 2.9577\n",
      "0m 10s (- 17m 32s) (400 0%) 2.8226\n",
      "0m 12s (- 17m 8s) (500 1%) 2.8124\n",
      "0m 15s (- 16m 36s) (600 1%) 2.7360\n",
      "0m 17s (- 16m 19s) (700 1%) 2.7871\n",
      "0m 19s (- 16m 20s) (800 1%) 2.7793\n",
      "0m 22s (- 16m 18s) (900 2%) 2.8150\n",
      "0m 25s (- 16m 22s) (1000 2%) 2.8402\n",
      "0m 27s (- 16m 33s) (1100 2%) 2.7464\n",
      "0m 32s (- 17m 31s) (1200 2%) 2.6716\n",
      "0m 36s (- 18m 1s) (1300 3%) 2.7219\n",
      "0m 40s (- 18m 53s) (1400 3%) 2.6794\n",
      "0m 44s (- 19m 16s) (1500 3%) 2.5827\n",
      "0m 48s (- 19m 30s) (1600 3%) 2.6698\n",
      "0m 53s (- 20m 9s) (1700 4%) 2.6470\n",
      "0m 57s (- 20m 31s) (1800 4%) 2.6580\n",
      "1m 1s (- 20m 45s) (1900 4%) 2.6411\n",
      "1m 5s (- 20m 55s) (2000 4%) 2.6749\n",
      "1m 10s (- 21m 12s) (2100 5%) 2.6077\n",
      "1m 14s (- 21m 30s) (2200 5%) 2.6726\n",
      "1m 19s (- 21m 45s) (2300 5%) 2.5735\n",
      "1m 23s (- 21m 57s) (2400 5%) 2.5459\n",
      "1m 28s (- 22m 9s) (2500 6%) 2.6169\n",
      "1m 30s (- 21m 55s) (2600 6%) 2.6146\n",
      "1m 35s (- 22m 10s) (2700 6%) 2.6166\n",
      "1m 40s (- 22m 19s) (2800 6%) 2.5944\n",
      "1m 44s (- 22m 31s) (2900 7%) 2.5305\n",
      "1m 49s (- 22m 37s) (3000 7%) 2.5386\n",
      "1m 54s (- 22m 47s) (3100 7%) 2.5721\n",
      "1m 58s (- 22m 57s) (3200 7%) 2.5048\n",
      "2m 1s (- 22m 44s) (3300 8%) 2.5340\n",
      "2m 4s (- 22m 31s) (3400 8%) 2.4909\n",
      "2m 7s (- 22m 21s) (3500 8%) 2.4859\n",
      "2m 10s (- 22m 11s) (3600 8%) 2.4309\n",
      "2m 13s (- 22m 1s) (3700 9%) 2.3770\n",
      "2m 16s (- 21m 51s) (3800 9%) 2.4204\n",
      "2m 19s (- 21m 40s) (3900 9%) 2.4123\n",
      "2m 22s (- 21m 31s) (4000 9%) 2.3563\n",
      "2m 25s (- 21m 19s) (4100 10%) 2.3775\n",
      "2m 27s (- 21m 5s) (4200 10%) 2.3036\n",
      "2m 30s (- 20m 55s) (4300 10%) 2.3754\n",
      "2m 34s (- 20m 56s) (4400 10%) 2.2734\n",
      "2m 38s (- 21m 0s) (4500 11%) 2.1898\n",
      "2m 41s (- 20m 54s) (4600 11%) 2.2836\n",
      "2m 44s (- 20m 46s) (4700 11%) 2.2422\n",
      "2m 48s (- 20m 40s) (4800 11%) 2.1822\n",
      "2m 50s (- 20m 32s) (4900 12%) 2.2170\n",
      "2m 53s (- 20m 22s) (5000 12%) 2.0753\n",
      "2m 56s (- 20m 17s) (5100 12%) 2.1578\n",
      "2m 59s (- 20m 9s) (5200 12%) 2.0784\n",
      "3m 1s (- 19m 58s) (5300 13%) 1.8822\n",
      "3m 4s (- 19m 48s) (5400 13%) 2.0718\n",
      "3m 6s (- 19m 40s) (5500 13%) 2.0893\n",
      "3m 11s (- 19m 42s) (5600 13%) 2.0539\n",
      "3m 15s (- 19m 45s) (5700 14%) 1.9458\n",
      "3m 18s (- 19m 39s) (5800 14%) 1.8655\n",
      "3m 21s (- 19m 32s) (5900 14%) 1.8368\n",
      "3m 23s (- 19m 21s) (6000 14%) 1.8365\n",
      "3m 27s (- 19m 18s) (6100 15%) 1.9596\n",
      "3m 31s (- 19m 19s) (6200 15%) 1.8701\n",
      "3m 35s (- 19m 22s) (6300 15%) 1.9104\n",
      "3m 40s (- 19m 23s) (6400 15%) 1.8222\n",
      "3m 44s (- 19m 23s) (6500 16%) 1.8462\n",
      "3m 48s (- 19m 24s) (6600 16%) 1.8613\n",
      "3m 53s (- 19m 27s) (6700 16%) 1.8846\n",
      "3m 56s (- 19m 25s) (6800 16%) 1.7801\n",
      "4m 1s (- 19m 25s) (6900 17%) 1.7207\n",
      "4m 5s (- 19m 25s) (7000 17%) 1.7017\n",
      "4m 9s (- 19m 26s) (7100 17%) 1.6900\n",
      "4m 14s (- 19m 28s) (7200 17%) 1.6318\n",
      "4m 19s (- 19m 29s) (7300 18%) 1.7668\n",
      "4m 23s (- 19m 27s) (7400 18%) 1.5214\n",
      "4m 27s (- 19m 27s) (7500 18%) 1.5331\n",
      "4m 32s (- 19m 28s) (7600 18%) 1.6097\n",
      "4m 36s (- 19m 29s) (7700 19%) 1.5653\n",
      "4m 41s (- 19m 30s) (7800 19%) 1.6604\n",
      "4m 46s (- 19m 31s) (7900 19%) 1.5589\n",
      "4m 50s (- 19m 29s) (8000 19%) 1.4612\n",
      "4m 54s (- 19m 29s) (8100 20%) 1.4530\n",
      "4m 59s (- 19m 30s) (8200 20%) 1.5652\n",
      "5m 4s (- 19m 30s) (8300 20%) 1.4710\n",
      "5m 8s (- 19m 30s) (8400 20%) 1.5770\n",
      "5m 13s (- 19m 30s) (8500 21%) 1.5472\n",
      "5m 17s (- 19m 29s) (8600 21%) 1.4862\n",
      "5m 23s (- 19m 31s) (8700 21%) 1.5252\n",
      "5m 27s (- 19m 31s) (8800 21%) 1.4723\n",
      "5m 33s (- 19m 32s) (8900 22%) 1.3848\n",
      "5m 38s (- 19m 33s) (9000 22%) 1.3499\n",
      "5m 42s (- 19m 32s) (9100 22%) 1.3996\n",
      "5m 47s (- 19m 32s) (9200 22%) 1.3639\n",
      "5m 52s (- 19m 33s) (9300 23%) 1.4549\n",
      "5m 56s (- 19m 30s) (9400 23%) 1.4071\n",
      "6m 1s (- 19m 29s) (9500 23%) 1.2588\n",
      "6m 6s (- 19m 29s) (9600 23%) 1.2155\n",
      "6m 11s (- 19m 28s) (9700 24%) 1.2455\n",
      "6m 16s (- 19m 28s) (9800 24%) 1.3294\n",
      "6m 20s (- 19m 25s) (9900 24%) 1.3705\n",
      "6m 25s (- 19m 24s) (10000 24%) 1.2694\n",
      "6m 29s (- 19m 21s) (10100 25%) 1.3386\n",
      "6m 33s (- 19m 19s) (10200 25%) 1.2176\n",
      "6m 38s (- 19m 18s) (10300 25%) 1.3483\n",
      "6m 43s (- 19m 17s) (10400 25%) 1.2958\n",
      "6m 48s (- 19m 16s) (10500 26%) 1.1436\n",
      "6m 53s (- 19m 15s) (10600 26%) 1.2562\n",
      "6m 58s (- 19m 14s) (10700 26%) 1.1394\n",
      "7m 2s (- 19m 11s) (10800 26%) 1.0813\n",
      "7m 7s (- 19m 10s) (10900 27%) 1.1846\n",
      "7m 12s (- 19m 8s) (11000 27%) 1.2364\n",
      "7m 16s (- 19m 6s) (11100 27%) 1.2317\n",
      "7m 22s (- 19m 6s) (11200 27%) 1.3439\n",
      "7m 27s (- 19m 5s) (11300 28%) 1.3479\n",
      "7m 31s (- 19m 3s) (11400 28%) 1.2275\n",
      "7m 36s (- 19m 1s) (11500 28%) 1.2300\n",
      "7m 41s (- 18m 58s) (11600 28%) 1.1863\n",
      "7m 45s (- 18m 56s) (11700 29%) 1.0762\n",
      "7m 50s (- 18m 53s) (11800 29%) 1.0713\n",
      "7m 55s (- 18m 51s) (11900 29%) 1.0819\n",
      "7m 59s (- 18m 49s) (12000 29%) 1.1525\n",
      "8m 4s (- 18m 46s) (12100 30%) 1.1367\n",
      "8m 9s (- 18m 44s) (12200 30%) 1.0195\n",
      "8m 13s (- 18m 42s) (12300 30%) 1.1230\n",
      "8m 18s (- 18m 40s) (12400 30%) 1.1044\n",
      "8m 23s (- 18m 37s) (12500 31%) 1.2075\n",
      "8m 28s (- 18m 34s) (12600 31%) 0.9322\n",
      "8m 31s (- 18m 29s) (12700 31%) 1.1839\n",
      "8m 36s (- 18m 27s) (12800 31%) 0.9928\n",
      "8m 40s (- 18m 23s) (12900 32%) 0.9760\n",
      "8m 45s (- 18m 21s) (13000 32%) 1.2036\n",
      "8m 49s (- 18m 17s) (13100 32%) 0.9720\n",
      "8m 54s (- 18m 14s) (13200 32%) 1.0143\n",
      "8m 59s (- 18m 12s) (13300 33%) 1.0362\n",
      "9m 3s (- 18m 9s) (13400 33%) 1.0623\n",
      "9m 8s (- 18m 5s) (13500 33%) 1.1246\n",
      "9m 12s (- 18m 1s) (13600 33%) 1.1418\n",
      "9m 15s (- 17m 56s) (13700 34%) 0.9416\n",
      "9m 20s (- 17m 53s) (13800 34%) 0.8896\n",
      "9m 24s (- 17m 50s) (13900 34%) 1.0680\n",
      "9m 27s (- 17m 42s) (14000 34%) 0.9843\n",
      "9m 31s (- 17m 39s) (14100 35%) 1.0587\n",
      "9m 35s (- 17m 35s) (14200 35%) 0.9907\n",
      "9m 38s (- 17m 29s) (14300 35%) 0.9421\n",
      "9m 41s (- 17m 23s) (14400 35%) 1.0642\n",
      "9m 44s (- 17m 17s) (14500 36%) 0.9572\n",
      "9m 46s (- 17m 10s) (14600 36%) 0.8919\n",
      "9m 49s (- 17m 3s) (14700 36%) 0.9984\n",
      "9m 51s (- 16m 57s) (14800 36%) 0.9276\n",
      "9m 54s (- 16m 50s) (14900 37%) 0.9368\n",
      "9m 56s (- 16m 43s) (15000 37%) 1.0031\n",
      "9m 58s (- 16m 37s) (15100 37%) 0.9240\n",
      "10m 1s (- 16m 30s) (15200 37%) 0.9841\n",
      "10m 4s (- 16m 24s) (15300 38%) 0.9614\n",
      "10m 6s (- 16m 18s) (15400 38%) 0.7779\n",
      "10m 9s (- 16m 12s) (15500 38%) 0.9379\n",
      "10m 11s (- 16m 5s) (15600 38%) 0.9229\n",
      "10m 13s (- 15m 59s) (15700 39%) 0.9358\n",
      "10m 16s (- 15m 53s) (15800 39%) 0.7849\n",
      "10m 20s (- 15m 49s) (15900 39%) 0.9298\n",
      "10m 25s (- 15m 46s) (16000 39%) 0.8155\n",
      "10m 28s (- 15m 42s) (16100 40%) 0.8482\n",
      "10m 32s (- 15m 39s) (16200 40%) 0.8200\n",
      "10m 38s (- 15m 37s) (16300 40%) 0.9354\n",
      "10m 43s (- 15m 35s) (16400 40%) 0.8539\n",
      "10m 48s (- 15m 32s) (16500 41%) 0.8463\n",
      "10m 51s (- 15m 28s) (16600 41%) 1.0625\n",
      "10m 56s (- 15m 25s) (16700 41%) 0.8834\n",
      "11m 1s (- 15m 23s) (16800 41%) 0.9748\n",
      "11m 6s (- 15m 20s) (16900 41%) 0.9526\n",
      "11m 10s (- 15m 17s) (17000 42%) 0.9624\n",
      "11m 15s (- 15m 14s) (17100 42%) 0.8044\n",
      "11m 20s (- 15m 11s) (17200 42%) 0.8251\n",
      "11m 25s (- 15m 9s) (17300 42%) 0.8713\n",
      "11m 30s (- 15m 6s) (17400 43%) 0.8713\n",
      "11m 35s (- 15m 3s) (17500 43%) 0.7466\n",
      "11m 40s (- 15m 0s) (17600 43%) 0.9284\n",
      "11m 44s (- 14m 57s) (17700 43%) 0.8637\n",
      "11m 49s (- 14m 54s) (17800 44%) 0.7464\n",
      "11m 54s (- 14m 51s) (17900 44%) 0.8054\n",
      "11m 59s (- 14m 49s) (18000 44%) 0.7447\n",
      "12m 4s (- 14m 45s) (18100 44%) 0.8421\n",
      "12m 7s (- 14m 41s) (18200 45%) 0.8003\n",
      "12m 12s (- 14m 38s) (18300 45%) 0.7946\n",
      "12m 17s (- 14m 35s) (18400 45%) 0.8895\n",
      "12m 22s (- 14m 32s) (18500 45%) 0.8053\n",
      "12m 27s (- 14m 29s) (18600 46%) 0.7919\n",
      "12m 31s (- 14m 26s) (18700 46%) 0.8637\n",
      "12m 37s (- 14m 23s) (18800 46%) 0.7787\n",
      "12m 42s (- 14m 20s) (18900 46%) 0.7836\n",
      "12m 47s (- 14m 17s) (19000 47%) 0.7224\n",
      "12m 51s (- 14m 14s) (19100 47%) 0.7828\n",
      "12m 56s (- 14m 11s) (19200 47%) 0.7796\n",
      "13m 1s (- 14m 8s) (19300 47%) 0.7763\n",
      "13m 5s (- 14m 4s) (19400 48%) 0.7826\n",
      "13m 10s (- 14m 0s) (19500 48%) 0.7496\n",
      "13m 15s (- 13m 57s) (19600 48%) 0.6351\n",
      "13m 20s (- 13m 54s) (19700 48%) 0.9277\n",
      "13m 24s (- 13m 50s) (19800 49%) 0.7284\n",
      "13m 29s (- 13m 47s) (19900 49%) 0.7568\n",
      "13m 34s (- 13m 44s) (20000 49%) 0.7937\n",
      "13m 38s (- 13m 40s) (20100 49%) 0.8525\n",
      "13m 43s (- 13m 36s) (20200 50%) 0.8389\n",
      "13m 47s (- 13m 32s) (20300 50%) 0.7719\n",
      "13m 52s (- 13m 29s) (20400 50%) 0.8006\n",
      "13m 56s (- 13m 25s) (20500 50%) 0.6954\n",
      "14m 1s (- 13m 21s) (20600 51%) 0.6362\n",
      "14m 5s (- 13m 18s) (20700 51%) 0.7973\n",
      "14m 9s (- 13m 14s) (20800 51%) 0.6915\n",
      "14m 14s (- 13m 10s) (20900 51%) 0.6533\n",
      "14m 18s (- 13m 6s) (21000 52%) 0.7005\n",
      "14m 23s (- 13m 2s) (21100 52%) 0.7416\n",
      "14m 28s (- 12m 59s) (21200 52%) 0.6867\n",
      "14m 32s (- 12m 55s) (21300 52%) 0.8469\n",
      "14m 36s (- 12m 51s) (21400 53%) 0.7906\n",
      "14m 40s (- 12m 47s) (21500 53%) 0.7291\n",
      "14m 44s (- 12m 43s) (21600 53%) 0.6705\n",
      "14m 48s (- 12m 38s) (21700 53%) 0.6297\n",
      "14m 50s (- 12m 33s) (21800 54%) 0.6268\n",
      "14m 53s (- 12m 28s) (21900 54%) 0.5813\n",
      "14m 56s (- 12m 23s) (22000 54%) 0.8115\n",
      "14m 59s (- 12m 17s) (22100 54%) 0.6101\n",
      "15m 1s (- 12m 12s) (22200 55%) 0.6558\n",
      "15m 4s (- 12m 7s) (22300 55%) 0.5780\n",
      "15m 7s (- 12m 2s) (22400 55%) 0.6840\n",
      "15m 9s (- 11m 57s) (22500 55%) 0.6999\n",
      "15m 12s (- 11m 52s) (22600 56%) 0.6863\n",
      "15m 14s (- 11m 46s) (22700 56%) 0.4718\n",
      "15m 17s (- 11m 41s) (22800 56%) 0.6623\n",
      "15m 19s (- 11m 36s) (22900 56%) 0.6611\n",
      "15m 21s (- 11m 31s) (23000 57%) 0.6904\n",
      "15m 24s (- 11m 25s) (23100 57%) 0.6956\n",
      "15m 26s (- 11m 20s) (23200 57%) 0.6996\n",
      "15m 28s (- 11m 15s) (23300 57%) 0.5846\n",
      "15m 31s (- 11m 10s) (23400 58%) 0.6582\n",
      "15m 33s (- 11m 5s) (23500 58%) 0.6517\n",
      "15m 36s (- 11m 0s) (23600 58%) 0.7263\n",
      "15m 38s (- 10m 55s) (23700 58%) 0.6469\n",
      "15m 40s (- 10m 49s) (23800 59%) 0.5480\n",
      "15m 43s (- 10m 44s) (23900 59%) 0.6102\n",
      "15m 45s (- 10m 39s) (24000 59%) 0.7083\n",
      "15m 47s (- 10m 34s) (24100 59%) 0.5834\n",
      "15m 49s (- 10m 29s) (24200 60%) 0.7750\n",
      "15m 52s (- 10m 24s) (24300 60%) 0.6404\n",
      "15m 54s (- 10m 19s) (24400 60%) 0.6746\n",
      "15m 56s (- 10m 14s) (24500 60%) 0.5714\n",
      "15m 58s (- 10m 9s) (24600 61%) 0.6349\n",
      "16m 0s (- 10m 4s) (24700 61%) 0.6457\n",
      "16m 3s (- 9m 59s) (24800 61%) 0.7871\n",
      "16m 5s (- 9m 54s) (24900 61%) 0.7489\n",
      "16m 7s (- 9m 50s) (25000 62%) 0.6228\n",
      "16m 10s (- 9m 45s) (25100 62%) 0.6638\n",
      "16m 12s (- 9m 40s) (25200 62%) 0.7008\n",
      "16m 14s (- 9m 35s) (25300 62%) 0.6064\n",
      "16m 17s (- 9m 30s) (25400 63%) 0.6002\n",
      "16m 19s (- 9m 26s) (25500 63%) 0.5026\n",
      "16m 22s (- 9m 21s) (25600 63%) 0.6383\n",
      "16m 24s (- 9m 16s) (25700 63%) 0.5562\n",
      "16m 26s (- 9m 12s) (25800 64%) 0.6129\n",
      "16m 29s (- 9m 7s) (25900 64%) 0.6295\n",
      "16m 31s (- 9m 2s) (26000 64%) 0.5320\n",
      "16m 33s (- 8m 58s) (26100 64%) 0.5885\n",
      "16m 35s (- 8m 53s) (26200 65%) 0.5527\n",
      "16m 38s (- 8m 49s) (26300 65%) 0.5463\n",
      "16m 40s (- 8m 44s) (26400 65%) 0.4701\n",
      "16m 42s (- 8m 39s) (26500 65%) 0.7472\n",
      "16m 45s (- 8m 35s) (26600 66%) 0.5334\n",
      "16m 47s (- 8m 31s) (26700 66%) 0.6985\n",
      "16m 50s (- 8m 26s) (26800 66%) 0.7687\n",
      "16m 52s (- 8m 22s) (26900 66%) 0.5659\n",
      "16m 54s (- 8m 17s) (27000 67%) 0.6019\n",
      "16m 57s (- 8m 13s) (27100 67%) 0.6737\n",
      "16m 59s (- 8m 8s) (27200 67%) 0.4484\n",
      "17m 1s (- 8m 4s) (27300 67%) 0.4894\n",
      "17m 4s (- 8m 0s) (27400 68%) 0.5467\n",
      "17m 6s (- 7m 55s) (27500 68%) 0.5396\n",
      "17m 8s (- 7m 51s) (27600 68%) 0.4481\n",
      "17m 11s (- 7m 46s) (27700 68%) 0.6040\n",
      "17m 13s (- 7m 42s) (27800 69%) 0.5812\n",
      "17m 16s (- 7m 38s) (27900 69%) 0.6122\n",
      "17m 18s (- 7m 33s) (28000 69%) 0.4897\n",
      "17m 20s (- 7m 29s) (28100 69%) 0.6209\n",
      "17m 23s (- 7m 25s) (28200 70%) 0.5887\n",
      "17m 25s (- 7m 21s) (28300 70%) 0.5549\n",
      "17m 27s (- 7m 16s) (28400 70%) 0.5390\n",
      "17m 30s (- 7m 12s) (28500 70%) 0.6446\n",
      "17m 32s (- 7m 8s) (28600 71%) 0.5745\n",
      "17m 35s (- 7m 4s) (28700 71%) 0.5889\n",
      "17m 37s (- 7m 0s) (28800 71%) 0.6556\n",
      "17m 39s (- 6m 55s) (28900 71%) 0.6059\n",
      "17m 42s (- 6m 51s) (29000 72%) 0.4652\n",
      "17m 44s (- 6m 47s) (29100 72%) 0.5124\n",
      "17m 47s (- 6m 43s) (29200 72%) 0.4777\n",
      "17m 49s (- 6m 39s) (29300 72%) 0.5089\n",
      "17m 52s (- 6m 35s) (29400 73%) 0.6011\n",
      "17m 54s (- 6m 31s) (29500 73%) 0.6263\n",
      "17m 56s (- 6m 27s) (29600 73%) 0.4508\n",
      "17m 59s (- 6m 23s) (29700 73%) 0.4903\n",
      "18m 1s (- 6m 18s) (29800 74%) 0.5090\n",
      "18m 4s (- 6m 14s) (29900 74%) 0.4857\n",
      "18m 6s (- 6m 10s) (30000 74%) 0.5710\n",
      "18m 9s (- 6m 6s) (30100 74%) 0.5372\n",
      "18m 11s (- 6m 2s) (30200 75%) 0.6298\n",
      "18m 13s (- 5m 58s) (30300 75%) 0.4810\n",
      "18m 16s (- 5m 54s) (30400 75%) 0.5393\n",
      "18m 18s (- 5m 50s) (30500 75%) 0.5407\n",
      "18m 21s (- 5m 46s) (30600 76%) 0.4902\n",
      "18m 23s (- 5m 42s) (30700 76%) 0.4603\n",
      "18m 26s (- 5m 39s) (30800 76%) 0.4879\n",
      "18m 28s (- 5m 35s) (30900 76%) 0.4995\n",
      "18m 30s (- 5m 31s) (31000 77%) 0.5037\n",
      "18m 33s (- 5m 27s) (31100 77%) 0.6122\n",
      "18m 35s (- 5m 23s) (31200 77%) 0.5732\n",
      "18m 38s (- 5m 19s) (31300 77%) 0.5598\n",
      "18m 40s (- 5m 15s) (31400 78%) 0.5462\n",
      "18m 43s (- 5m 11s) (31500 78%) 0.5524\n",
      "18m 45s (- 5m 7s) (31600 78%) 0.5482\n",
      "18m 48s (- 5m 3s) (31700 78%) 0.4174\n",
      "18m 50s (- 5m 0s) (31800 79%) 0.4179\n",
      "18m 52s (- 4m 56s) (31900 79%) 0.4152\n",
      "18m 55s (- 4m 52s) (32000 79%) 0.4130\n",
      "18m 57s (- 4m 48s) (32100 79%) 0.4565\n",
      "18m 59s (- 4m 44s) (32200 80%) 0.4951\n",
      "19m 2s (- 4m 40s) (32300 80%) 0.5014\n",
      "19m 4s (- 4m 37s) (32400 80%) 0.4475\n",
      "19m 7s (- 4m 33s) (32500 80%) 0.5241\n",
      "19m 9s (- 4m 29s) (32600 81%) 0.3984\n",
      "19m 11s (- 4m 25s) (32700 81%) 0.5967\n",
      "19m 14s (- 4m 21s) (32800 81%) 0.4473\n",
      "19m 16s (- 4m 18s) (32900 81%) 0.3995\n",
      "19m 19s (- 4m 14s) (33000 82%) 0.4329\n",
      "19m 21s (- 4m 10s) (33100 82%) 0.6009\n",
      "19m 23s (- 4m 6s) (33200 82%) 0.5460\n",
      "19m 26s (- 4m 3s) (33300 82%) 0.5745\n",
      "19m 28s (- 3m 59s) (33400 83%) 0.3636\n",
      "19m 31s (- 3m 55s) (33500 83%) 0.6145\n",
      "19m 33s (- 3m 51s) (33600 83%) 0.4665\n",
      "19m 36s (- 3m 48s) (33700 83%) 0.5442\n",
      "19m 38s (- 3m 44s) (33800 83%) 0.4898\n",
      "19m 40s (- 3m 40s) (33900 84%) 0.3976\n",
      "19m 43s (- 3m 37s) (34000 84%) 0.5063\n",
      "19m 45s (- 3m 33s) (34100 84%) 0.5240\n",
      "19m 48s (- 3m 29s) (34200 84%) 0.4757\n",
      "19m 50s (- 3m 26s) (34300 85%) 0.5207\n",
      "19m 52s (- 3m 22s) (34400 85%) 0.4926\n",
      "19m 55s (- 3m 18s) (34500 85%) 0.5425\n",
      "19m 57s (- 3m 15s) (34600 85%) 0.4249\n",
      "19m 59s (- 3m 11s) (34700 86%) 0.3380\n",
      "20m 1s (- 3m 7s) (34800 86%) 0.4751\n",
      "20m 3s (- 3m 4s) (34900 86%) 0.5383\n",
      "20m 6s (- 3m 0s) (35000 86%) 0.5639\n",
      "20m 8s (- 2m 57s) (35100 87%) 0.4754\n",
      "20m 11s (- 2m 53s) (35200 87%) 0.3765\n",
      "20m 13s (- 2m 49s) (35300 87%) 0.6186\n",
      "20m 15s (- 2m 46s) (35400 87%) 0.4983\n",
      "20m 18s (- 2m 42s) (35500 88%) 0.3904\n",
      "20m 20s (- 2m 39s) (35600 88%) 0.3574\n",
      "20m 22s (- 2m 35s) (35700 88%) 0.3979\n",
      "20m 25s (- 2m 31s) (35800 88%) 0.4595\n",
      "20m 27s (- 2m 28s) (35900 89%) 0.4665\n",
      "20m 30s (- 2m 24s) (36000 89%) 0.4365\n",
      "20m 32s (- 2m 21s) (36100 89%) 0.4652\n",
      "20m 34s (- 2m 17s) (36200 89%) 0.3279\n",
      "20m 37s (- 2m 14s) (36300 90%) 0.3377\n",
      "20m 39s (- 2m 10s) (36400 90%) 0.3065\n",
      "20m 42s (- 2m 7s) (36500 90%) 0.4229\n",
      "20m 44s (- 2m 3s) (36600 90%) 0.3735\n",
      "20m 46s (- 2m 0s) (36700 91%) 0.5512\n",
      "20m 49s (- 1m 56s) (36800 91%) 0.4441\n",
      "20m 51s (- 1m 53s) (36900 91%) 0.6445\n",
      "20m 54s (- 1m 49s) (37000 91%) 0.4242\n",
      "20m 56s (- 1m 46s) (37100 92%) 0.5686\n",
      "20m 58s (- 1m 42s) (37200 92%) 0.3958\n",
      "21m 1s (- 1m 39s) (37300 92%) 0.4106\n",
      "21m 3s (- 1m 35s) (37400 92%) 0.3808\n",
      "21m 5s (- 1m 32s) (37500 93%) 0.5857\n",
      "21m 8s (- 1m 29s) (37600 93%) 0.3781\n",
      "21m 10s (- 1m 25s) (37700 93%) 0.4714\n",
      "21m 13s (- 1m 22s) (37800 93%) 0.4727\n",
      "21m 15s (- 1m 18s) (37900 94%) 0.3276\n",
      "21m 17s (- 1m 15s) (38000 94%) 0.4581\n",
      "21m 20s (- 1m 11s) (38100 94%) 0.3905\n",
      "21m 22s (- 1m 8s) (38200 94%) 0.4913\n",
      "21m 25s (- 1m 5s) (38300 95%) 0.4242\n",
      "21m 27s (- 1m 1s) (38400 95%) 0.3996\n",
      "21m 29s (- 0m 58s) (38500 95%) 0.4205\n",
      "21m 32s (- 0m 54s) (38600 95%) 0.5910\n",
      "21m 34s (- 0m 51s) (38700 96%) 0.4577\n",
      "21m 36s (- 0m 48s) (38800 96%) 0.5013\n",
      "21m 39s (- 0m 44s) (38900 96%) 0.5697\n",
      "21m 41s (- 0m 41s) (39000 96%) 0.4717\n",
      "21m 43s (- 0m 38s) (39100 97%) 0.3399\n",
      "21m 46s (- 0m 34s) (39200 97%) 0.4612\n",
      "21m 48s (- 0m 31s) (39300 97%) 0.3702\n",
      "21m 51s (- 0m 27s) (39400 97%) 0.4383\n",
      "21m 53s (- 0m 24s) (39500 98%) 0.4701\n",
      "21m 55s (- 0m 21s) (39600 98%) 0.3712\n",
      "21m 58s (- 0m 17s) (39700 98%) 0.3080\n",
      "22m 0s (- 0m 14s) (39800 98%) 0.4302\n",
      "22m 3s (- 0m 11s) (39900 99%) 0.3958\n",
      "22m 5s (- 0m 7s) (40000 99%) 0.3761\n",
      "22m 7s (- 0m 4s) (40100 99%) 0.4344\n",
      "22m 10s (- 0m 1s) (40200 99%) 0.4850\n"
     ]
    }
   ],
   "source": [
    "trainBatch(encoder2, decoder2, epochs=4, beam_width=1, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> pei\n",
      "= ꯄꯩ\n",
      "< ꯄꯩ<EOS>\n",
      "\n",
      "> yourakpada\n",
      "= ꯌꯧꯔꯛꯄꯗ\n",
      "< ꯌꯧꯔꯛꯄꯗ<EOS>\n",
      "\n",
      "> khangnaribashi\n",
      "= ꯈꯪꯅꯔꯤꯕꯁꯤ\n",
      "< ꯈꯪꯍꯔꯥꯡꯅꯤꯁ<EOS>\n",
      "\n",
      "> laagumna\n",
      "= ꯂꯥꯒꯨꯝꯅ\n",
      "< ꯂꯥꯒꯒꯝꯅ<EOS>\n",
      "\n",
      "> sabitri\n",
      "= ꯁꯥꯕꯤꯇ꯭ꯔꯤ\n",
      "< ꯁꯥꯢꯕ꯭ꯔꯤ<EOS>\n",
      "\n",
      "> kakchinglakpa\n",
      "= ꯀꯛꯆꯤꯡꯂꯥꯛꯄ\n",
      "< ꯀꯥꯢꯆꯪꯂꯛꯄꯄ<EOS>\n",
      "\n",
      "> waaba\n",
      "= ꯋꯥꯕ\n",
      "< ꯋꯥꯕ<EOS>\n",
      "\n",
      "> soitapa\n",
      "= ꯁꯣꯢꯇꯄ\n",
      "< ꯁꯤꯢꯇꯄ<EOS>\n",
      "\n",
      "> apaamba\n",
      "= ꯑꯄꯥꯝꯕ\n",
      "< ꯑꯄꯥꯝꯕ<EOS>\n",
      "\n",
      "> iriba\n",
      "= ꯏꯔꯤꯕ\n",
      "< ꯏꯔꯤꯕ<EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair = random.choice(pairs)\n",
    "\n",
    "# print(pair[0])\n",
    "# print(pair[1])\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     input_tensor = tensorFromWord(input_lang, pair[0])\n",
    "#     input_length = input_tensor.size()[0]\n",
    "#     encoder1_hidden = encoder1.initHidden()\n",
    "\n",
    "#     encoder1_outputs = torch.zeros(MAX_LENGTH, encoder1.hidden_size, device=device)\n",
    "\n",
    "#     if encoder1.cell_type == 'lstm':\n",
    "#         encoder1_cell = encoder1.initHidden()\n",
    "\n",
    "#     for ei in range(input_length):\n",
    "#         if encoder1.cell_type == 'lstm':\n",
    "#             encoder1_output, encoder1_hidden, encoder1_cell = encoder1(input_tensor[ei], encoder1_hidden, encoder1_cell)\n",
    "#         else:\n",
    "#             encoder1_output, encoder1_hidden = encoder1(input_tensor[ei], encoder1_hidden)\n",
    "            \n",
    "#         encoder1_outputs[ei] += encoder1_output[0, 0]\n",
    "\n",
    "#     decoder1_hidden = encoder1_hidden\n",
    "\n",
    "#     if encoder1.cell_type == 'lstm':\n",
    "#         decoder1_cell = encoder1_cell\n",
    "\n",
    "#     decoded_chars = \"\"\n",
    "\n",
    "#     # Predict the output using beam search\n",
    "#     predicted_seq = decoder1.beam_search(encoder1_outputs, decoder1_hidden, 5, SOS_token, EOS_token)\n",
    "\n",
    "#     # Convert the predicted sequence to a word\n",
    "#     for char_idx in predicted_seq:\n",
    "#         decoded_chars += output_lang.index2char[char_idx]\n",
    "\n",
    "#     print(decoded_chars)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55"
      ]
     },
     "execution_count": 1266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalAccuracy(encoder2, decoder2, valid_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_configuration = {\n",
    "    'method': 'bayes',\n",
    "    'name': 'bayes-sweep',\n",
    "    'metric': {\n",
    "        'name': 'val_accuracy',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'epochs': {\n",
    "            'values': [2] #[5, 10] \n",
    "        },\n",
    "        'embedding_size': {\n",
    "            'values': [64, 128, 256] \n",
    "        },\n",
    "        'num_hidden_layers': {\n",
    "            'values': [1, 2, 3]\n",
    "        },\n",
    "        'hidden_layer_size': {\n",
    "            'values': [64, 128, 256] \n",
    "        },\n",
    "        'cell_type': {\n",
    "            'values': ['rnn', 'gru', 'lstm'] \n",
    "        },\n",
    "        'learning_rate': {\n",
    "            'values': [1e-2, 5e-3, 1e-3, 5e-4] \n",
    "        },\n",
    "        'optimizer': {\n",
    "            'values': ['SGD', 'Adam'] \n",
    "        },\n",
    "        'dropout': {\n",
    "            'values': [0.0, 0.2, 0.3] \n",
    "        },\n",
    "        'beam_width': {\n",
    "            'values': [1] #[1, 3, 5]\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_search():\n",
    "    run = wandb.init(project='hyperparam-search-enc-dec', reinit=True)\n",
    "    config = wandb.config\n",
    "    wandb.run.name = f'hl_{config.num_hidden_layers}_sz_{config.hidden_layer_size}_ct_{config.cell_type}_lr_{config.learning_rate}_opt_{config.optimizer}_do_{config.dropout}_bw_{config.beam_width}_em_{config.embedding_size}'\n",
    "    \n",
    "    encoder = EncoderRNN(input_lang.n_chars, config.embedding_size, config.hidden_layer_size, config.num_hidden_layers, dropout=config.dropout, cell_type=config.cell_type).to(device)\n",
    "    decoder = DecoderRNN(config.hidden_layer_size, config.embedding_size, output_lang.n_chars, config.num_hidden_layers, dropout=config.dropout, cell_type=config.cell_type).to(device)\n",
    "\n",
    "    if config.optimizer == 'SGD':\n",
    "        optimizer = optim.SGD\n",
    "    elif config.optimizer == 'Adam':\n",
    "        optimizer = optim.Adam\n",
    "\n",
    "    trainBatch(encoder, decoder, config.epochs, optimizer=optimizer, beam_width=config.beam_width, print_every=100, learning_rate=config.learning_rate, log=True)\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: g9uq8j54\n",
      "Sweep URL: https://wandb.ai/abdullah_010/hyperparam-search-seq2seq/sweeps/g9uq8j54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fxioify8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_hidden_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67638b8afe53415ab041f5045538ced9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668691882902445, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/abdullah/Desktop/Courses/Sem6/CS6910/A3/wandb/run-20230512_031232-fxioify8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/abdullah_010/hyperparam-search-seq2seq/runs/fxioify8' target=\"_blank\">atomic-sweep-1</a></strong> to <a href='https://wandb.ai/abdullah_010/hyperparam-search-seq2seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/abdullah_010/hyperparam-search-seq2seq/sweeps/g9uq8j54' target=\"_blank\">https://wandb.ai/abdullah_010/hyperparam-search-seq2seq/sweeps/g9uq8j54</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/abdullah_010/hyperparam-search-seq2seq' target=\"_blank\">https://wandb.ai/abdullah_010/hyperparam-search-seq2seq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/abdullah_010/hyperparam-search-seq2seq/sweeps/g9uq8j54' target=\"_blank\">https://wandb.ai/abdullah_010/hyperparam-search-seq2seq/sweeps/g9uq8j54</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/abdullah_010/hyperparam-search-seq2seq/runs/fxioify8' target=\"_blank\">https://wandb.ai/abdullah_010/hyperparam-search-seq2seq/runs/fxioify8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 3s (- 10m 19s) (100 0%) 2.8159\n",
      "0m 5s (- 9m 28s) (200 0%) 2.8134\n",
      "0m 8s (- 9m 15s) (300 1%) 2.9135\n",
      "0m 11s (- 9m 2s) (400 1%) 2.7394\n",
      "0m 13s (- 8m 52s) (500 2%) 2.8498\n",
      "0m 15s (- 8m 39s) (600 2%) 2.7626\n",
      "0m 18s (- 8m 29s) (700 3%) 2.8047\n",
      "0m 21s (- 8m 29s) (800 3%) 2.8329\n",
      "0m 23s (- 8m 26s) (900 4%) 2.7512\n",
      "0m 26s (- 8m 31s) (1000 4%) 2.6743\n",
      "0m 29s (- 8m 38s) (1100 5%) 2.7370\n",
      "0m 33s (- 8m 42s) (1200 5%) 2.7835\n",
      "0m 36s (- 8m 51s) (1300 6%) 2.6994\n",
      "0m 39s (- 8m 49s) (1400 6%) 2.7232\n",
      "0m 42s (- 8m 44s) (1500 7%) 2.6434\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_configuration, project='hyperparam-search-seq2seq')\n",
    "wandb.agent(sweep_id, hyperparameter_search, count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
